{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMDTr9TlaNAp8gMDJcG+FS3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/divyansh-ag-03/NLP-CSL448/blob/main/NLP_WordNet_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Experiment 12\n",
        "##Write a program to read text data from a file and perform pre-processing, Word Sense Disambiguation and list of synonyms, antonyms, hypernyms and hyponyms of every word as obtained from the lexical ontology WordNet."
      ],
      "metadata": {
        "id": "kY5UC_cfuVBe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ja1k2nmFop9A",
        "outputId": "be265804-2da9-436a-fb17-ac0ff9637006"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8VfnCMm5m8wW"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('all')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-_7dDNVoroG",
        "outputId": "da30a103-1a29-4a8c-b2fd-2a23ae2f9133"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_rus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_rus.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker_tab to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker_tab.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger_tab to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/maxent_treebank_pos_tagger_tab.zip.\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package tagsets_json to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets_json.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2022 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet2022.zip.\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(text):\n",
        "  tokens = word_tokenize(text)\n",
        "  words = [word.lower() for word in tokens if word.isalpha()]\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "  words = [lemmatizer.lemmatize(word) for word in words]\n",
        "\n",
        "  return words"
      ],
      "metadata": {
        "id": "JukaKFh_o5SK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def word_sense_disambiguation(word):\n",
        "  synsets = wordnet.synsets(word)\n",
        "  if synsets:\n",
        "    return synsets[0]\n",
        "  else:\n",
        "    return None"
      ],
      "metadata": {
        "id": "JSQD4lgvpkEl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_word_info(word):\n",
        "  sense = word_sense_disambiguation(word)\n",
        "\n",
        "  if sense:\n",
        "    synonyms = [lemma.name() for lemma in sense.lemmas()]\n",
        "    antonyms = []\n",
        "\n",
        "    for lemma in sense.lemmas():\n",
        "      antonyms.extend(lemma.antonyms())\n",
        "\n",
        "    antonyms = [antonym.name() for antonym in antonyms]\n",
        "\n",
        "    hypernyms = [hypernym.name() for hypernym in sense.hypernyms()]\n",
        "\n",
        "    hyponyms = [hyponym.name() for hyponym in sense.hyponyms()]\n",
        "\n",
        "    return {\n",
        "        'Synonyms': synonyms,\n",
        "        'Antonyms': antonyms,\n",
        "        'Hypernyms': hypernyms,\n",
        "        'Hyponyms': hyponyms\n",
        "    }\n",
        "\n",
        "  else:\n",
        "    return None"
      ],
      "metadata": {
        "id": "o1OrL3EUp7mp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(file_path):\n",
        "  with open(file_path, 'r', encoding = 'utf-8') as file:\n",
        "    text = file.read()\n",
        "\n",
        "  words = preprocess(text)\n",
        "\n",
        "  word_info_dict = {}\n",
        "  for word in words:\n",
        "    if word not in word_info_dict:\n",
        "      word_info = get_word_info(word)\n",
        "      if word_info:\n",
        "        word_info_dict[word] = word_info\n",
        "\n",
        "  for word, info in word_info_dict.items():\n",
        "    print(f\"Word: {word}\")\n",
        "    print(f\"Synonyms: {','.join(info['Synonyms'])}\")\n",
        "    print(f\"Antonyms: {','.join(info['Antonyms'])}\")\n",
        "    print(f\"Hypernyms: {','.join(info['Hypernyms'])}\")\n",
        "    print(f\"Hyponyms: {','.join(info['Hyponyms'])}\")\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "I08z22fmqy5i"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "  main('/content/Poem.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzCmNHFvswMi",
        "outputId": "bd34bf84-24a0-42c7-cf2c-315b1721280d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word: two\n",
            "Synonyms: two,2,II,deuce\n",
            "Antonyms: \n",
            "Hypernyms: digit.n.01\n",
            "Hyponyms: couple.n.04,craps.n.01\n",
            "\n",
            "\n",
            "Word: road\n",
            "Synonyms: road,route\n",
            "Antonyms: \n",
            "Hypernyms: way.n.06\n",
            "Hyponyms: access_road.n.01,byway.n.01,causeway.n.01,clearway.n.01,corduroy.n.02,detour.n.01,drive.n.11,driveway.n.01,highway.n.01,line.n.14,post_road.n.01,roadway.n.01,shortcut.n.01,side_road.n.01,skid_road.n.02,speedway.n.01,thoroughfare.n.01,track.n.10,turnoff.n.02\n",
            "\n",
            "\n",
            "Word: diverged\n",
            "Synonyms: diverge\n",
            "Antonyms: converge\n",
            "Hypernyms: move.v.03\n",
            "Hyponyms: branch.v.02\n",
            "\n",
            "\n",
            "Word: in\n",
            "Synonyms: inch,in\n",
            "Antonyms: \n",
            "Hypernyms: linear_unit.n.01\n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: a\n",
            "Synonyms: angstrom,angstrom_unit,A\n",
            "Antonyms: \n",
            "Hypernyms: metric_linear_unit.n.01\n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: yellow\n",
            "Synonyms: yellow,yellowness\n",
            "Antonyms: \n",
            "Hypernyms: chromatic_color.n.01\n",
            "Hyponyms: amber.n.01,brownish_yellow.n.01,canary_yellow.n.01,gamboge.n.02,greenish_yellow.n.01,old_gold.n.01,orange_yellow.n.01,pale_yellow.n.01\n",
            "\n",
            "\n",
            "Word: wood\n",
            "Synonyms: wood\n",
            "Antonyms: \n",
            "Hypernyms: plant_material.n.01\n",
            "Hyponyms: alder.n.01,ash.n.03,balsa.n.01,bamboo.n.01,basswood.n.01,beech.n.02,beefwood.n.02,bentwood.n.01,birch.n.01,black_locust.n.01,blackwood.n.01,boxwood.n.01,brazilwood.n.01,briarwood.n.01,brushwood.n.01,burl.n.01,cabinet_wood.n.01,cedar.n.02,cherry.n.01,chestnut.n.01,citronwood.n.01,cocuswood.n.01,cypress.n.01,dogwood.n.02,driftwood.n.01,dyewood.n.01,ebony.n.02,elm.n.02,eucalyptus.n.01,fir.n.01,fruitwood.n.01,granadilla_wood.n.01,guaiac_wood.n.01,gumwood.n.01,hardwood.n.01,hazel.n.02,heartwood.n.01,hemlock.n.03,hickory.n.01,incense_wood.n.01,ironwood.n.02,kauri.n.03,kingwood.n.01,knot.n.03,lancewood.n.01,larch.n.01,lemonwood.n.01,lignum_vitae.n.01,locust.n.02,log.n.01,logwood.n.01,mahogany.n.01,maple.n.01,matchwood.n.01,matchwood.n.02,oak.n.01,obeche.n.01,olive.n.03,orangewood.n.01,panama_redwood.n.01,pecan.n.01,pine.n.02,poon.n.01,poplar.n.01,pyinma.n.01,raw_wood.n.01,red_lauan.n.01,redwood.n.01,rosewood.n.01,ruby_wood.n.01,sabicu.n.01,sandalwood.n.01,sandarac.n.01,sapwood.n.01,satinwood.n.02,sawdust.n.01,shittimwood.n.03,silver_quandong.n.01,softwood.n.01,spruce.n.01,sumac.n.01,sycamore.n.01,teak.n.01,tulipwood.n.01,tulipwood.n.02,tupelo.n.01,walnut.n.02,wicker.n.01,yellowwood.n.01,yew.n.01,zebrawood.n.01\n",
            "\n",
            "\n",
            "Word: sorry\n",
            "Synonyms: regretful,sorry,bad\n",
            "Antonyms: unregretful\n",
            "Hypernyms: \n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: i\n",
            "Synonyms: iodine,iodin,I,atomic_number_53\n",
            "Antonyms: \n",
            "Hypernyms: chemical_element.n.01,halogen.n.01\n",
            "Hyponyms: iodine-125.n.01,iodine-131.n.01\n",
            "\n",
            "\n",
            "Word: not\n",
            "Synonyms: not,non\n",
            "Antonyms: \n",
            "Hypernyms: \n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: travel\n",
            "Synonyms: travel,traveling,travelling\n",
            "Antonyms: \n",
            "Hypernyms: motion.n.06\n",
            "Hyponyms: air_travel.n.01,circumnavigation.n.01,commutation.n.01,crossing.n.01,driving.n.02,journey.n.01,junketing.n.01,on_the_road.n.01,peregrination.n.01,riding.n.02,stage.n.06,staging.n.03,traversal.n.02,walk.n.04,wandering.n.01,water_travel.n.01,wayfaring.n.01\n",
            "\n",
            "\n",
            "Word: both\n",
            "Synonyms: both\n",
            "Antonyms: \n",
            "Hypernyms: \n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: be\n",
            "Synonyms: beryllium,Be,glucinium,atomic_number_4\n",
            "Antonyms: \n",
            "Hypernyms: metallic_element.n.01\n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: one\n",
            "Synonyms: one,1,I,ace,single,unity\n",
            "Antonyms: \n",
            "Hypernyms: digit.n.01\n",
            "Hyponyms: monad.n.02,singleton.n.01\n",
            "\n",
            "\n",
            "Word: traveller\n",
            "Synonyms: traveler,traveller\n",
            "Antonyms: \n",
            "Hypernyms: person.n.01\n",
            "Hyponyms: absentee.n.01,air_traveler.n.01,arrival.n.03,astronaut.n.01,business_traveler.n.01,carrier.n.01,companion.n.02,entrant.n.03,flier.n.01,follower.n.02,foreigner.n.01,hosteller.n.02,messenger.n.01,migrant.n.01,motorcyclist.n.01,mover.n.03,musher.n.01,passenger.n.01,pedestrian.n.01,raftsman.n.01,rider.n.01,rider.n.03,runner.n.02,scourer.n.02,swimmer.n.02,tourist.n.01,transient.n.01,trekker.n.01,visitor.n.01,voyager.n.01,wanderer.n.01,wayfarer.n.02\n",
            "\n",
            "\n",
            "Word: long\n",
            "Synonyms: hanker,long,yearn\n",
            "Antonyms: \n",
            "Hypernyms: desire.v.01\n",
            "Hyponyms: ache.v.02\n",
            "\n",
            "\n",
            "Word: stood\n",
            "Synonyms: stand,stand_up\n",
            "Antonyms: sit,lie\n",
            "Hypernyms: rest.v.01\n",
            "Hyponyms: line_up.v.03,ramp.v.05,stand_back.v.02\n",
            "\n",
            "\n",
            "Word: looked\n",
            "Synonyms: look\n",
            "Antonyms: \n",
            "Hypernyms: \n",
            "Hyponyms: admire.v.02,eye.v.01,gaze.v.01,give_the_eye.v.01,give_the_glad_eye.v.01,glance.v.01,gloat.v.02,goggle.v.01,leer.v.01,look_around.v.01,look_away.v.01,look_back.v.01,ogle.v.01,peep.v.01,peer.v.01,regard.v.02,squint.v.02,stare.v.02,take_a_look.v.01\n",
            "\n",
            "\n",
            "Word: down\n",
            "Synonyms: down,down_feather\n",
            "Antonyms: \n",
            "Hypernyms: feather.n.01\n",
            "Hyponyms: duck_down.n.01,goose_down.n.01,plumule.n.01,swan's_down.n.02\n",
            "\n",
            "\n",
            "Word: far\n",
            "Synonyms: Army_for_the_Liberation_of_Rwanda,ALIR,Former_Armed_Forces,FAR,Interahamwe\n",
            "Antonyms: \n",
            "Hypernyms: \n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: it\n",
            "Synonyms: information_technology,IT\n",
            "Antonyms: \n",
            "Hypernyms: engineering.n.02\n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: bent\n",
            "Synonyms: bent,set\n",
            "Antonyms: \n",
            "Hypernyms: inclination.n.01\n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: undergrowth\n",
            "Synonyms: underbrush,undergrowth,underwood\n",
            "Antonyms: \n",
            "Hypernyms: brush.n.01\n",
            "Hyponyms: groundcover.n.02\n",
            "\n",
            "\n",
            "Word: then\n",
            "Synonyms: then\n",
            "Antonyms: \n",
            "Hypernyms: point.n.06\n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: took\n",
            "Synonyms: take\n",
            "Antonyms: \n",
            "Hypernyms: act.v.01\n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: other\n",
            "Synonyms: other\n",
            "Antonyms: same\n",
            "Hypernyms: \n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: just\n",
            "Synonyms: just\n",
            "Antonyms: unjust\n",
            "Hypernyms: \n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: fair\n",
            "Synonyms: carnival,fair,funfair\n",
            "Antonyms: \n",
            "Hypernyms: show.n.01\n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: having\n",
            "Synonyms: have,have_got,hold\n",
            "Antonyms: \n",
            "Hypernyms: \n",
            "Hyponyms: bear.v.11,carry.v.21,keep.v.03,keep.v.07,keep.v.19,keep.v.20,monopolize.v.02,stock.v.01,sustain.v.04,wield.v.01\n",
            "\n",
            "\n",
            "Word: perhaps\n",
            "Synonyms: possibly,perchance,perhaps,maybe,mayhap,peradventure\n",
            "Antonyms: \n",
            "Hypernyms: \n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: better\n",
            "Synonyms: better\n",
            "Antonyms: \n",
            "Hypernyms: good.n.03\n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: claim\n",
            "Synonyms: claim\n",
            "Antonyms: \n",
            "Hypernyms: assertion.n.01\n",
            "Hyponyms: cause_of_action.n.01,dibs.n.01,pretension.n.02\n",
            "\n",
            "\n",
            "Word: wa\n",
            "Synonyms: Washington,Evergreen_State,WA\n",
            "Antonyms: \n",
            "Hypernyms: \n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: grassy\n",
            "Synonyms: grassy\n",
            "Antonyms: grassless\n",
            "Hypernyms: \n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: wanted\n",
            "Synonyms: desire,want\n",
            "Antonyms: \n",
            "Hypernyms: \n",
            "Hyponyms: ambition.v.01,crave.v.01,envy.v.02,fancy.v.02,feel_like.v.01,hanker.v.01,hope.v.02,itch.v.04,like.v.05,lust_after.v.01,miss.v.02,seek.v.01,wish.v.01,wish.v.02,wish.v.04\n",
            "\n",
            "\n",
            "Word: wear\n",
            "Synonyms: wear\n",
            "Antonyms: \n",
            "Hypernyms: deterioration.n.01\n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: though\n",
            "Synonyms: though\n",
            "Antonyms: \n",
            "Hypernyms: \n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: passing\n",
            "Synonyms: pass,passing_play,passing_game,passing\n",
            "Antonyms: \n",
            "Hypernyms: football_play.n.01\n",
            "Hyponyms: forward_pass.n.01,lateral_pass.n.01,spot_pass.n.01\n",
            "\n",
            "\n",
            "Word: there\n",
            "Synonyms: there\n",
            "Antonyms: here\n",
            "Hypernyms: location.n.01\n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: had\n",
            "Synonyms: have,have_got,hold\n",
            "Antonyms: \n",
            "Hypernyms: \n",
            "Hyponyms: bear.v.11,carry.v.21,keep.v.03,keep.v.07,keep.v.19,keep.v.20,monopolize.v.02,stock.v.01,sustain.v.04,wield.v.01\n",
            "\n",
            "\n",
            "Word: worn\n",
            "Synonyms: wear,have_on\n",
            "Antonyms: \n",
            "Hypernyms: \n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: really\n",
            "Synonyms: truly,genuinely,really\n",
            "Antonyms: \n",
            "Hypernyms: \n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: about\n",
            "Synonyms: about,astir\n",
            "Antonyms: \n",
            "Hypernyms: \n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: same\n",
            "Synonyms: Lapp,Lapplander,Sami,Saami,Same,Saame\n",
            "Antonyms: \n",
            "Hypernyms: european.n.01\n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: morning\n",
            "Synonyms: morning,morn,morning_time,forenoon\n",
            "Antonyms: \n",
            "Hypernyms: time_period.n.01\n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: equally\n",
            "Synonyms: equally,as,every_bit\n",
            "Antonyms: \n",
            "Hypernyms: \n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: lay\n",
            "Synonyms: ballad,lay\n",
            "Antonyms: \n",
            "Hypernyms: song.n.01\n",
            "Hyponyms: minstrelsy.n.02\n",
            "\n",
            "\n",
            "Word: leaf\n",
            "Synonyms: leaf,leafage,foliage\n",
            "Antonyms: \n",
            "Hypernyms: plant_organ.n.01\n",
            "Hyponyms: amplexicaul_leaf.n.01,blade.n.01,cataphyll.n.01,compound_leaf.n.01,crenate_leaf.n.01,dandelion_green.n.01,dentate_leaf.n.01,emarginate_leaf.n.01,entire_leaf.n.01,erose_leaf.n.01,fig_leaf.n.01,floral_leaf.n.01,frond.n.01,greenery.n.01,leaflet.n.02,lobed_leaf.n.01,pad.n.02,parallel-veined_leaf.n.01,parted_leaf.n.01,pitcher.n.04,prickly-edged_leaf.n.01,rosette.n.03,runcinate_leaf.n.01,scale.n.04,serrate_leaf.n.01,simple_leaf.n.01,sporophyll.n.01\n",
            "\n",
            "\n",
            "Word: no\n",
            "Synonyms: no\n",
            "Antonyms: yes\n",
            "Hypernyms: negative.n.01\n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: step\n",
            "Synonyms: measure,step\n",
            "Antonyms: \n",
            "Hypernyms: maneuver.n.04\n",
            "Hyponyms: countermeasure.n.01,precaution.n.01,shark_repellent.n.01\n",
            "\n",
            "\n",
            "Word: trodden\n",
            "Synonyms: step,tread\n",
            "Antonyms: \n",
            "Hypernyms: travel.v.01\n",
            "Hyponyms: step_on.v.01\n",
            "\n",
            "\n",
            "Word: black\n",
            "Synonyms: black,blackness,inkiness\n",
            "Antonyms: white\n",
            "Hypernyms: achromatic_color.n.01\n",
            "Hyponyms: coal_black.n.01\n",
            "\n",
            "\n",
            "Word: oh\n",
            "Synonyms: Ohio,Buckeye_State,OH\n",
            "Antonyms: \n",
            "Hypernyms: \n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: kept\n",
            "Synonyms: keep,maintain,hold\n",
            "Antonyms: \n",
            "Hypernyms: \n",
            "Hyponyms: conserve.v.01,continue.v.03,distance.v.01,hold_over.v.03,housekeep.v.01,preserve.v.06,pressurize.v.02\n",
            "\n",
            "\n",
            "Word: first\n",
            "Synonyms: first,number_one\n",
            "Antonyms: \n",
            "Hypernyms: rank.n.02\n",
            "Hyponyms: former.n.01\n",
            "\n",
            "\n",
            "Word: another\n",
            "Synonyms: another,some_other\n",
            "Antonyms: \n",
            "Hypernyms: \n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: day\n",
            "Synonyms: day,twenty-four_hours,twenty-four_hour_period,24-hour_interval,solar_day,mean_solar_day\n",
            "Antonyms: \n",
            "Hypernyms: time_unit.n.01\n",
            "Hyponyms: date.n.01,date.n.07,eve.n.02,morrow.n.01,today.n.02,tomorrow.n.01,yesterday.n.01\n",
            "\n",
            "\n",
            "Word: yet\n",
            "Synonyms: yet\n",
            "Antonyms: \n",
            "Hypernyms: \n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: knowing\n",
            "Synonyms: knowing\n",
            "Antonyms: \n",
            "Hypernyms: higher_cognitive_process.n.01\n",
            "Hyponyms: awareness.n.01,cognizance.n.02,incognizance.n.01,know.n.01,prevision.n.03,understanding.n.01\n",
            "\n",
            "\n",
            "Word: way\n",
            "Synonyms: manner,mode,style,way,fashion\n",
            "Antonyms: \n",
            "Hypernyms: property.n.02\n",
            "Hyponyms: artistic_style.n.01,drape.n.02,fit.n.03,form.n.11,life_style.n.01,response.n.07,setup.n.02,touch.n.04,wise.n.01\n",
            "\n",
            "\n",
            "Word: lead\n",
            "Synonyms: lead\n",
            "Antonyms: \n",
            "Hypernyms: advantage.n.01\n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: on\n",
            "Synonyms: on\n",
            "Antonyms: off\n",
            "Hypernyms: \n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: doubted\n",
            "Synonyms: doubt\n",
            "Antonyms: \n",
            "Hypernyms: disbelieve.v.01\n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: ever\n",
            "Synonyms: ever,of_all_time\n",
            "Antonyms: \n",
            "Hypernyms: \n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: come\n",
            "Synonyms: semen,seed,seminal_fluid,ejaculate,cum,come\n",
            "Antonyms: \n",
            "Hypernyms: liquid_body_substance.n.01\n",
            "Hyponyms: milt.n.02\n",
            "\n",
            "\n",
            "Word: back\n",
            "Synonyms: back,dorsum\n",
            "Antonyms: \n",
            "Hypernyms: body_part.n.01\n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: telling\n",
            "Synonyms: relation,telling,recounting\n",
            "Antonyms: \n",
            "Hypernyms: narration.n.02\n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: sigh\n",
            "Synonyms: sigh,suspiration\n",
            "Antonyms: \n",
            "Hypernyms: utterance.n.01\n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: somewhere\n",
            "Synonyms: somewhere\n",
            "Antonyms: \n",
            "Hypernyms: location.n.01\n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: age\n",
            "Synonyms: age\n",
            "Antonyms: \n",
            "Hypernyms: property.n.02\n",
            "Hyponyms: bone_age.n.01,chronological_age.n.01,developmental_age.n.01,fetal_age.n.01,mental_age.n.01,newness.n.01,oldness.n.01,oldness.n.02,youngness.n.01\n",
            "\n",
            "\n",
            "Word: hence\n",
            "Synonyms: therefore,hence,thence,thus,so\n",
            "Antonyms: \n",
            "Hypernyms: \n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: le\n",
            "Synonyms: lupus_erythematosus,LE\n",
            "Antonyms: \n",
            "Hypernyms: autoimmune_disease.n.01,lupus.n.01\n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: travelled\n",
            "Synonyms: travel,go,move,locomote\n",
            "Antonyms: stay_in_place\n",
            "Hypernyms: \n",
            "Hyponyms: accompany.v.02,advance.v.01,angle.v.01,ascend.v.01,automobile.v.01,back.v.02,bang.v.04,beetle.v.02,betake_oneself.v.01,billow.v.02,bounce.v.03,breeze.v.02,caravan.v.01,career.v.01,carry.v.36,circle.v.01,circle.v.02,circuit.v.01,circulate.v.07,come.v.01,come.v.11,crawl.v.01,cruise.v.02,derail.v.02,descend.v.01,do.v.13,drag.v.04,draw.v.12,drive.v.02,drive.v.14,ease.v.01,fall.v.01,fall.v.15,ferry.v.03,float.v.01,float.v.02,float.v.05,flock.v.01,fly.v.01,fly.v.06,follow.v.01,follow.v.04,forge.v.05,get_around.v.04,ghost.v.01,glide.v.01,go_around.v.02,hiss.v.02,hurtle.v.01,island_hop.v.01,lance.v.01,lurch.v.03,outflank.v.01,pace.v.02,pan.v.01,pass.v.01,pass_over.v.04,play.v.09,plow.v.03,prance.v.02,precede.v.04,precess.v.01,proceed.v.02,propagate.v.02,pursue.v.02,push.v.09,raft.v.02,repair.v.03,retreat.v.02,retrograde.v.02,return.v.01,ride.v.01,ride.v.04,ride.v.10,rise.v.01,roll.v.12,round.v.01,run.v.11,run.v.34,rush.v.01,scramble.v.01,seek.v.04,shuttle.v.01,sift.v.01,ski.v.01,slice_into.v.01,slither.v.01,snowshoe.v.01,speed.v.04,steamer.v.01,step.v.01,step.v.02,step.v.06,stray.v.02,swap.v.02,swash.v.01,swim.v.01,swim.v.05,swing.v.03,taxi.v.01,trail.v.03,tram.v.01,transfer.v.06,travel.v.04,travel.v.05,travel.v.06,travel_by.v.01,travel_purposefully.v.01,travel_rapidly.v.01,trundle.v.01,turn.v.06,walk.v.01,walk.v.10,weave.v.04,wend.v.01,wheel.v.03,whine.v.01,whish.v.02,whisk.v.02,whistle.v.02,withdraw.v.01,zigzag.v.01,zoom.v.02\n",
            "\n",
            "\n",
            "Word: by\n",
            "Synonyms: by,past\n",
            "Antonyms: \n",
            "Hypernyms: \n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: ha\n",
            "Synonyms: hour_angle,HA\n",
            "Antonyms: \n",
            "Hypernyms: angular_distance.n.01\n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: made\n",
            "Synonyms: make,do\n",
            "Antonyms: \n",
            "Hypernyms: \n",
            "Hyponyms: overdo.v.01\n",
            "\n",
            "\n",
            "Word: all\n",
            "Synonyms: all\n",
            "Antonyms: some,no\n",
            "Hypernyms: \n",
            "Hyponyms: \n",
            "\n",
            "\n",
            "Word: difference\n",
            "Synonyms: difference\n",
            "Antonyms: sameness\n",
            "Hypernyms: quality.n.01\n",
            "Hyponyms: differentia.n.01,differential.n.02,discrepancy.n.01,dissimilarity.n.01,distinction.n.04,inequality.n.01,otherness.n.01,variety.n.06\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aO6qjuGTtObN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}